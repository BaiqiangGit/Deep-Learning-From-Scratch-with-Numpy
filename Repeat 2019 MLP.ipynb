{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I am stupid enough to forget, so I repeat to remember"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. fetch mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_mnist():\n",
    "    \n",
    "    ## load libs\n",
    "    import os\n",
    "    from six.moves import urllib\n",
    "    from scipy.io import loadmat\n",
    "\n",
    "    ## make dir\n",
    "    if not os.path.exists('datasets'):\n",
    "        os.mkdir('datasets')\n",
    "    \n",
    "    ## download mnist\n",
    "    mnist_path = \"./datasets/mnist-original.mat\"\n",
    "    mnist_alternative_url = \"https://github.com/amplab/datascience-sp14/raw/master/lab7/mldata/mnist-original.mat\"\n",
    "    response = urllib.request.urlopen(mnist_alternative_url)\n",
    "    if not os.path.exists(mnist_path):\n",
    "        with open(mnist_path, 'wb') as f:\n",
    "            content = response.read()\n",
    "            f.write(content)\n",
    "            \n",
    "    ## load mnist\n",
    "    mnist_raw = loadmat(mnist_path)\n",
    "    mnist = {'data': mnist_raw['data'].T,\n",
    "             'target': mnist_raw['label'][0],\n",
    "             'COL_NAMES' : ['label', 'data'],\n",
    "             'DESCR': 'mldata.org dataset: mnist-original'}\n",
    "    \n",
    "    ## return mnist\n",
    "    return mnist, mnist['data'], mnist['target']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data\n",
    "print('a. Loading....: ', end = '')\n",
    "mnist, X, y = fetch_mnist()\n",
    "print('Original data shape', X.shape, ', target shape', y.shape)\n",
    "\n",
    "## reshape\n",
    "print('b. Reshaping..: ', end = '')\n",
    "X = X.T.reshape(28 * 28, -1)\n",
    "y = y.reshape(1,-1)\n",
    "print('Re-shaped data shape:', X.shape, ', target shape', y.shape)\n",
    "\n",
    "## check data range\n",
    "print('c. Scaling....: ', end = '')\n",
    "print('Scale Data to [0, 1]:')\n",
    "print('\\t\\tOriginal Range: Xmax-%d, Xmin-%d, ymax-%d, y-min-%d' % (X.max(), X.min(), y.max(), y.min()))\n",
    "X = X/255\n",
    "print('\\t\\tScaled Range: Xmax-%d, Xmin-%d, ymax-%d, y-min-%d' % (X.max(), X.min(), y.max(), y.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "X = X\n",
    "Y = OneHotEncoder().fit_transform(y.reshape(-1,1).astype('int8')).toarray().T\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Make train/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 60000\n",
    "X_train, Y_train = X[:,:m], Y[:,:m]\n",
    "X_test , Y_test  = X[:,m:], Y[:,m:]\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Shuffle train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = np.random.permutation(m)\n",
    "X_train, Y_train = X_train[:,shuffle], Y_train[:,shuffle]\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Visual check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "seed = 123456\n",
    "np.random.seed(seed)\n",
    "idx = np.random.randint(m)\n",
    "\n",
    "## visualize\n",
    "image = X_train[:,idx].squeeze().reshape(28, 28)\n",
    "label = np.argmax(Y_train[:,idx])\n",
    "\n",
    "plt.figure(figsize = (5, 5))\n",
    "plt.imshow(image, 'binary_r')\n",
    "plt.title('Visual Check: image index %d, label %d'%(idx, label))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Config MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## params\n",
    "num_samples = 60000\n",
    "batch_size  = 3000\n",
    "input_dims  = 784\n",
    "hidden_dims = 32\n",
    "output_dims = 10\n",
    "lr = 0.01\n",
    "epoches = 1000\n",
    "display_step = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize network as random weights, and bias as zeros\n",
    "W1 = np.random.randn(hidden_dims, input_dims)\n",
    "b1 = np.zeros((hidden_dims, 1))\n",
    "W2 = np.random.randn(output_dims, hidden_dims)\n",
    "b2 = np.zeros((output_dims, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Make/Train Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train 100 epoches\n",
    "for epoch in range(epoches):\n",
    "    \n",
    "    ## batching\n",
    "    samples = np.random.choice(num_samples, batch_size, replace=False)\n",
    "    X_batch = X_train[:, samples]\n",
    "    Y_batch = Y_train[:, samples]\n",
    "    \n",
    "    ## Forward\n",
    "    Z1 = W1 @ X_batch + b1 ## matrix multiplication: (32, 784) @ (784, 60000) \n",
    "    A1 = 1 / (1 + np.exp(-Z1)) ## sigmoid: 1/(1+np.exp(-x)).sum(axis = 1), (32, 60000)\n",
    "    Z2 = W2 @ A1 + b2 ## (10, 32) @ (32, 60000) ==> (10, 60000)\n",
    "    A2 = np.exp(Z2)/ np.exp(Z2).sum(axis = 0) ## softmax: (10, 60000)\n",
    "    \n",
    "    ## compute cross-entropy loss\n",
    "    ## loss = -sum(y_true * log(y_pred))/60000\n",
    "    Loss = -np.sum(Y_batch * np.log(A2)) / batch_size\n",
    "    \n",
    "    ## Compute gradient\n",
    "    dZ2 = A2 - Y_batch ## ce + softmax (10, 60000)\n",
    "    dW2 = dZ2 @ A1.T ## (10, 32) ==> (10, 60000) @ (60000, 32)\n",
    "    db2 = dZ2.sum(axis = 1, keepdims = True) / batch_size\n",
    "    \n",
    "    dA1 = W2.T @ dZ2 ## (32, 60000)\n",
    "    dZ1 = dA1 * A1 * (1 - A1)\n",
    "    dW1 = dZ1 @ X_batch.T\n",
    "    db1 = dZ1.sum(axis = 1, keepdims = True) / batch_size\n",
    "    \n",
    "    ## Backward\n",
    "    W1 -= dW1 * lr\n",
    "    W2 -= dW2 * lr\n",
    "    b1 -= db1 * lr\n",
    "    b2 -= db2 * lr\n",
    "    \n",
    "    if epoch % display_step == 0:\n",
    "        print('Epoch %2d, Loss %.4f'%(epoch, Loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Test Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## forward pass\n",
    "Z1 = W1 @ X_test + b1\n",
    "A1 = 1 / (1 + np.exp(-Z1))\n",
    "Z2 = W2 @ A1 + b2\n",
    "A2 = np.exp(Z2) / np.exp(Z2).sum(axis = 0)\n",
    "\n",
    "## generate results\n",
    "preds = np.argmax(A2, axis = 0)\n",
    "truth = np.argmax(Y_test, axis = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Calculate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import sklearn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(truth, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(truth, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(truth, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
