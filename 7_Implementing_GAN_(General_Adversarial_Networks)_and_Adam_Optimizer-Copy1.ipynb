{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "colab_type": "code",
    "id": "Q7wHOBdzu85R",
    "outputId": "7a65edde-0874-4ca1-db00-f2bd6522eb1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Load Data ----------\n",
      "-------- Load Data --------------------------------\n",
      "-------- Data shape: (10000, 784) , Labels shape\" (10000,)\n",
      "-------- Data Loaded --------------------------------\n",
      "--------- Declare Hyper Parameters ----------\n"
     ]
    }
   ],
   "source": [
    "## import libs\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "random_numer = int(12345)\n",
    "np.random.seed(random_numer)\n",
    "\n",
    "def ReLu(x):\n",
    "    mask = (x>0) * 1.0\n",
    "    return mask *x\n",
    "def d_ReLu(x):\n",
    "    mask = (x>0) * 1.0\n",
    "    return mask \n",
    "\n",
    "def arctan(x):\n",
    "    return np.arctan(x)\n",
    "def d_arctan(x):\n",
    "    return 1 / (1 + x ** 2)\n",
    "\n",
    "def log(x):\n",
    "    return 1 / ( 1+ np.exp(-1*x))\n",
    "def d_log(x):\n",
    "    return log(x) * (1 - log(x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "def d_tanh(x):\n",
    "    return 1 - np.tanh(x) ** 2\n",
    "\n",
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "# 1. Load Data and declare hyper\n",
    "print('--------- Load Data ----------')\n",
    "print('-------- Load Data --------------------------------')\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "images, labels = X_test.reshape(-1, 28*28), y_test ## use test set\n",
    "images, labels = shuffle(np.asarray(images),np.asarray(labels)) ## shuffle together\n",
    "print('-------- Data shape:', images.shape, ', Labels shape\"', labels.shape)\n",
    "print('-------- Data Loaded --------------------------------')\n",
    "\n",
    "\n",
    "num_epoch = 10\n",
    "learing_rate = 0.00009\n",
    "G_input = 100\n",
    "hidden_input,hidden_input2,hidden_input3 = 128,256,346\n",
    "hidden_input4,hidden_input5,hidden_input6 = 480,560,686\n",
    "\n",
    "\n",
    "\n",
    "print('--------- Declare Hyper Parameters ----------')\n",
    "# 2. Declare Weights\n",
    "D_W1 = np.random.normal(size=(784,hidden_input),scale=(1. / np.sqrt(784 / 2.)))   *0.002\n",
    "# D_b1 = np.random.normal(size=(128),scale=(1. / np.sqrt(128 / 2.)))       *0.002\n",
    "D_b1 = np.zeros(hidden_input)\n",
    "\n",
    "D_W2 = np.random.normal(size=(hidden_input,1),scale=(1. / np.sqrt(hidden_input / 2.)))     *0.002\n",
    "# D_b2 = np.random.normal(size=(1),scale=(1. / np.sqrt(1 / 2.)))           *0.002\n",
    "D_b2 = np.zeros(1)\n",
    "\n",
    "\n",
    "G_W1 = np.random.normal(size=(G_input,hidden_input),scale=(1. / np.sqrt(G_input / 2.)))   *0.002\n",
    "# G_b1 = np.random.normal(size=(128),scale=(1. / np.sqrt(128 / 2.)))      *0.002\n",
    "G_b1 = np.zeros(hidden_input)\n",
    "\n",
    "G_W2 = np.random.normal(size=(hidden_input,hidden_input2),scale=(1. / np.sqrt(hidden_input / 2.)))   *0.002\n",
    "# G_b1 = np.random.normal(size=(128),scale=(1. / np.sqrt(128 / 2.)))      *0.002\n",
    "G_b2 = np.zeros(hidden_input2)\n",
    "\n",
    "G_W3 = np.random.normal(size=(hidden_input2,hidden_input3),scale=(1. / np.sqrt(hidden_input2 / 2.)))   *0.002\n",
    "# G_b1 = np.random.normal(size=(128),scale=(1. / np.sqrt(128 / 2.)))      *0.002\n",
    "G_b3 = np.zeros(hidden_input3)\n",
    "\n",
    "G_W4 = np.random.normal(size=(hidden_input3,hidden_input4),scale=(1. / np.sqrt(hidden_input3 / 2.)))   *0.002\n",
    "# G_b1 = np.random.normal(size=(128),scale=(1. / np.sqrt(128 / 2.)))      *0.002\n",
    "G_b4 = np.zeros(hidden_input4)\n",
    "\n",
    "G_W5 = np.random.normal(size=(hidden_input4,hidden_input5),scale=(1. / np.sqrt(hidden_input4 / 2.)))   *0.002\n",
    "# G_b1 = np.random.normal(size=(128),scale=(1. / np.sqrt(128 / 2.)))      *0.002\n",
    "G_b5 = np.zeros(hidden_input5)\n",
    "\n",
    "G_W6 = np.random.normal(size=(hidden_input5,hidden_input6),scale=(1. / np.sqrt(hidden_input5 / 2.)))   *0.002\n",
    "# G_b1 = np.random.normal(size=(128),scale=(1. / np.sqrt(128 / 2.)))      *0.002\n",
    "G_b6 = np.zeros(hidden_input6)\n",
    "\n",
    "G_W7 = np.random.normal(size=(hidden_input6,784),scale=(1. / np.sqrt(hidden_input6 / 2.)))  *0.002\n",
    "# G_b2 = np.random.normal(size=(784),scale=(1. / np.sqrt(784 / 2.)))      *0.002\n",
    "G_b7 = np.zeros(784)\n",
    "\n",
    "# 3. For Adam Optimzier\n",
    "v1,m1 = 0,0\n",
    "v2,m2 = 0,0\n",
    "v3,m3 = 0,0\n",
    "v4,m4 = 0,0\n",
    "\n",
    "v5,m5 = 0,0\n",
    "v6,m6 = 0,0\n",
    "v7,m7 = 0,0\n",
    "v8,m8 = 0,0\n",
    "v9,m9 = 0,0\n",
    "v10,m10 = 0,0\n",
    "v11,m11 = 0,0\n",
    "v12,m12 = 0,0\n",
    "\n",
    "v13,m13 = 0,0\n",
    "v14,m14 = 0,0\n",
    "\n",
    "v15,m15 = 0,0\n",
    "v16,m16 = 0,0\n",
    "\n",
    "v17,m17 = 0,0\n",
    "v18,m18 = 0,0\n",
    "\n",
    "\n",
    "beta_1,beta_2,eps = 0.9,0.999,0.00000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "colab_type": "code",
    "id": "Q7wHOBdzu85R",
    "outputId": "7a65edde-0874-4ca1-db00-f2bd6522eb1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Started Training ----------\n",
      "Current Iter:  0  Current D cost: [[-0.00231923]]  Current G cost:  [[0.69319532]]\r",
      "--------- Show Example Result See Tab Above ----------\n",
      "--------- Wait for the image to load ---------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('--------- Started Training ----------')\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    random_int = np.random.randint(len(images) - 5)\n",
    "    current_image = np.expand_dims(images[random_int],axis=0)\n",
    "\n",
    "    # Func: Generate The first Fake Data\n",
    "    Z = np.random.uniform(-1., 1., size=[1, G_input])\n",
    "    Gl1 = Z.dot(G_W1) + G_b1\n",
    "    Gl1A = arctan(Gl1)\n",
    "    Gl2 = Gl1A.dot(G_W2) + G_b2\n",
    "    Gl2A = ReLu(Gl2)\n",
    "    Gl3 = Gl2A.dot(G_W3) + G_b3\n",
    "    Gl3A = arctan(Gl3)\n",
    "\n",
    "    Gl4 = Gl3A.dot(G_W4) + G_b4\n",
    "    Gl4A = ReLu(Gl4)\n",
    "    Gl5 = Gl4A.dot(G_W5) + G_b5\n",
    "    Gl5A = tanh(Gl5)\n",
    "    Gl6 = Gl5A.dot(G_W6) + G_b6\n",
    "    Gl6A = ReLu(Gl6)\n",
    "    Gl7 = Gl6A.dot(G_W7) + G_b7\n",
    "\n",
    "    current_fake_data = log(Gl7)\n",
    "\n",
    "    # Func: Forward Feed for Real data\n",
    "    Dl1_r = current_image.dot(D_W1) + D_b1\n",
    "    Dl1_rA = ReLu(Dl1_r)\n",
    "    Dl2_r = Dl1_rA.dot(D_W2) + D_b2\n",
    "    Dl2_rA = log(Dl2_r)\n",
    "\n",
    "    # Func: Forward Feed for Fake Data\n",
    "    Dl1_f = current_fake_data.dot(D_W1) + D_b1\n",
    "    Dl1_fA = ReLu(Dl1_f)\n",
    "    Dl2_f = Dl1_fA.dot(D_W2) + D_b2\n",
    "    Dl2_fA = log(Dl2_f)\n",
    "\n",
    "    # Func: Cost D\n",
    "    D_cost = -np.log(Dl2_rA) + np.log(1.0- Dl2_fA)\n",
    "\n",
    "    # Func: Gradient\n",
    "    grad_f_w2_part_1 =  1/(1.0- Dl2_fA)\n",
    "    grad_f_w2_part_2 =  d_log(Dl2_f)\n",
    "    grad_f_w2_part_3 =   Dl1_fA\n",
    "    grad_f_w2 =       grad_f_w2_part_3.T.dot(grad_f_w2_part_1 * grad_f_w2_part_2) \n",
    "    grad_f_b2 = grad_f_w2_part_1 * grad_f_w2_part_2\n",
    "\n",
    "    grad_f_w1_part_1 =  (grad_f_w2_part_1 * grad_f_w2_part_2).dot(D_W2.T)\n",
    "    grad_f_w1_part_2 =  d_ReLu(Dl1_f)\n",
    "    grad_f_w1_part_3 =   current_fake_data\n",
    "    grad_f_w1 =       grad_f_w1_part_3.T.dot(grad_f_w1_part_1 * grad_f_w1_part_2) \n",
    "    grad_f_b1 =      grad_f_w1_part_1 * grad_f_w1_part_2\n",
    "\n",
    "    grad_r_w2_part_1 =  - 1/Dl2_rA\n",
    "    grad_r_w2_part_2 =  d_log(Dl2_r)\n",
    "    grad_r_w2_part_3 =   Dl1_rA\n",
    "    grad_r_w2 =       grad_r_w2_part_3.T.dot(grad_r_w2_part_1 * grad_r_w2_part_2) \n",
    "    grad_r_b2 =       grad_r_w2_part_1 * grad_r_w2_part_2\n",
    "\n",
    "    grad_r_w1_part_1 =  (grad_r_w2_part_1 * grad_r_w2_part_2).dot(D_W2.T)\n",
    "    grad_r_w1_part_2 =  d_ReLu(Dl1_r)\n",
    "    grad_r_w1_part_3 =   current_image\n",
    "    grad_r_w1 =       grad_r_w1_part_3.T.dot(grad_r_w1_part_1 * grad_r_w1_part_2) \n",
    "    grad_r_b1 =       grad_r_w1_part_1 * grad_r_w1_part_2\n",
    "\n",
    "    grad_w1 =grad_f_w1 + grad_r_w1\n",
    "    grad_b1 =grad_f_b1 + grad_r_b1\n",
    "    \n",
    "    grad_w2 =grad_f_w2 + grad_r_w2\n",
    "    grad_b2 =grad_f_b2 + grad_r_b2\n",
    "\n",
    "    # ---- Update Gradient ----\n",
    "    m1 = beta_1 * m1 + (1 - beta_1) * grad_w1\n",
    "    v1 = beta_2 * v1 + (1 - beta_2) * grad_w1 ** 2\n",
    "\n",
    "    m2 = beta_1 * m2 + (1 - beta_1) * grad_b1\n",
    "    v2 = beta_2 * v2 + (1 - beta_2) * grad_b1 ** 2\n",
    "\n",
    "    m3 = beta_1 * m3 + (1 - beta_1) * grad_w2\n",
    "    v3 = beta_2 * v3 + (1 - beta_2) * grad_w2 ** 2\n",
    "\n",
    "    m4 = beta_1 * m4 + (1 - beta_1) * grad_b2\n",
    "    v4 = beta_2 * v4 + (1 - beta_2) * grad_b2 ** 2\n",
    "\n",
    "    D_W1 = D_W1 - (learing_rate / (np.sqrt(v1 /(1-beta_2) ) + eps)) * (m1/(1-beta_1))\n",
    "    D_b1 = D_b1 - (learing_rate / (np.sqrt(v2 /(1-beta_2) ) + eps)) * (m2/(1-beta_1))\n",
    "    \n",
    "    D_W2 = D_W2 - (learing_rate / (np.sqrt(v3 /(1-beta_2) ) + eps)) * (m3/(1-beta_1))\n",
    "    D_b2 = D_b2 - (learing_rate / (np.sqrt(v4 /(1-beta_2) ) + eps)) * (m4/(1-beta_1))\n",
    "\n",
    "    # Func: Forward Feed for G\n",
    "    Z = np.random.uniform(-1., 1., size=[1, G_input])\n",
    "    Gl1 = Z.dot(G_W1) + G_b1\n",
    "    Gl1A = arctan(Gl1)\n",
    "    Gl2 = Gl1A.dot(G_W2) + G_b2\n",
    "    Gl2A = ReLu(Gl2)\n",
    "    Gl3 = Gl2A.dot(G_W3) + G_b3\n",
    "    Gl3A = arctan(Gl3)\n",
    "\n",
    "    Gl4 = Gl3A.dot(G_W4) + G_b4\n",
    "    Gl4A = ReLu(Gl4)\n",
    "    Gl5 = Gl4A.dot(G_W5) + G_b5\n",
    "    Gl5A = tanh(Gl5)\n",
    "    Gl6 = Gl5A.dot(G_W6) + G_b6\n",
    "    Gl6A = ReLu(Gl6)\n",
    "    Gl7 = Gl6A.dot(G_W7) + G_b7\n",
    "    \n",
    "    current_fake_data = log(Gl7)\n",
    "\n",
    "    Dl1 = current_fake_data.dot(D_W1) + D_b1\n",
    "    Dl1_A = ReLu(Dl1)\n",
    "    Dl2 = Dl1_A.dot(D_W2) + D_b2\n",
    "    Dl2_A = log(Dl2)\n",
    "\n",
    "    # Func: Cost G\n",
    "    G_cost = -np.log(Dl2_fA)\n",
    "\n",
    "    # Func: Gradient\n",
    "    grad_G_w7_part_1 = ((-1/Dl2_fA) * d_log(Dl2_f).dot(D_W2.T) * (d_ReLu(Dl1_f))).dot(D_W1.T)\n",
    "    grad_G_w7_part_2 = d_log(Gl7)\n",
    "    grad_G_w7_part_3 = Gl6A\n",
    "    grad_G_w7 = grad_G_w7_part_3.T.dot(grad_G_w7_part_1 * grad_G_w7_part_1)\n",
    "    grad_G_b7 = grad_G_w7_part_1 * grad_G_w7_part_2\n",
    "\n",
    "    grad_G_w6_part_1 = (grad_G_w7_part_1 * grad_G_w7_part_2).dot(G_W7.T)\n",
    "    grad_G_w6_part_2 = d_ReLu(Gl6)\n",
    "    grad_G_w6_part_3 = Gl5A\n",
    "    grad_G_w6 = grad_G_w6_part_3.T.dot(grad_G_w6_part_1 * grad_G_w6_part_2)\n",
    "    grad_G_b6 = (grad_G_w6_part_1 * grad_G_w6_part_2)\n",
    "\n",
    "    grad_G_w5_part_1 = (grad_G_w6_part_1 * grad_G_w6_part_2).dot(G_W6.T)\n",
    "    grad_G_w5_part_2 = d_tanh(Gl5)\n",
    "    grad_G_w5_part_3 = Gl4A\n",
    "    grad_G_w5 = grad_G_w5_part_3.T.dot(grad_G_w5_part_1 * grad_G_w5_part_2)\n",
    "    grad_G_b5 = (grad_G_w5_part_1 * grad_G_w5_part_2)\n",
    "\n",
    "    grad_G_w4_part_1 = (grad_G_w5_part_1 * grad_G_w5_part_2).dot(G_W5.T)\n",
    "    grad_G_w4_part_2 = d_ReLu(Gl4)\n",
    "    grad_G_w4_part_3 = Gl3A\n",
    "    grad_G_w4 = grad_G_w4_part_3.T.dot(grad_G_w4_part_1 * grad_G_w4_part_2)\n",
    "    grad_G_b4 = (grad_G_w4_part_1 * grad_G_w4_part_2)\n",
    "\n",
    "    grad_G_w3_part_1 = (grad_G_w4_part_1 * grad_G_w4_part_2).dot(G_W4.T)\n",
    "    grad_G_w3_part_2 = d_arctan(Gl3)\n",
    "    grad_G_w3_part_3 = Gl2A\n",
    "    grad_G_w3 = grad_G_w3_part_3.T.dot(grad_G_w3_part_1 * grad_G_w3_part_2)\n",
    "    grad_G_b3 = (grad_G_w3_part_1 * grad_G_w3_part_2)\n",
    "\n",
    "    grad_G_w2_part_1 = (grad_G_w3_part_1 * grad_G_w3_part_2).dot(G_W3.T)\n",
    "    grad_G_w2_part_2 = d_ReLu(Gl2)\n",
    "    grad_G_w2_part_3 = Gl1A\n",
    "    grad_G_w2 = grad_G_w2_part_3.T.dot(grad_G_w2_part_1 * grad_G_w2_part_2)\n",
    "    grad_G_b2 = (grad_G_w2_part_1 * grad_G_w2_part_2)\n",
    "\n",
    "    grad_G_w1_part_1 = (grad_G_w2_part_1 * grad_G_w2_part_2).dot(G_W2.T)\n",
    "    grad_G_w1_part_2 = d_arctan(Gl1)\n",
    "    grad_G_w1_part_3 = Z\n",
    "    grad_G_w1 = grad_G_w1_part_3.T.dot(grad_G_w1_part_1 * grad_G_w1_part_2)\n",
    "    grad_G_b1 = grad_G_w1_part_1 * grad_G_w1_part_2\n",
    "\n",
    "    # ---- Update Gradient ----\n",
    "    m5 = beta_1 * m5 + (1 - beta_1) * grad_G_w1\n",
    "    v5 = beta_2 * v5 + (1 - beta_2) * grad_G_w1 ** 2\n",
    "\n",
    "    m6 = beta_1 * m6 + (1 - beta_1) * grad_G_b1\n",
    "    v6 = beta_2 * v6 + (1 - beta_2) * grad_G_b1 ** 2\n",
    "\n",
    "    m7 = beta_1 * m7 + (1 - beta_1) * grad_G_w2\n",
    "    v7 = beta_2 * v7 + (1 - beta_2) * grad_G_w2 ** 2\n",
    "\n",
    "    m8 = beta_1 * m8 + (1 - beta_1) * grad_G_b2\n",
    "    v8 = beta_2 * v8 + (1 - beta_2) * grad_G_b2 ** 2\n",
    "\n",
    "    m9 = beta_1 * m9 + (1 - beta_1) * grad_G_w3\n",
    "    v9 = beta_2 * v9 + (1 - beta_2) * grad_G_w3 ** 2\n",
    "\n",
    "    m10 = beta_1 * m10 + (1 - beta_1) * grad_G_b3\n",
    "    v10 = beta_2 * v10 + (1 - beta_2) * grad_G_b3 ** 2\n",
    "\n",
    "    m11 = beta_1 * m11 + (1 - beta_1) * grad_G_w4\n",
    "    v11 = beta_2 * v11 + (1 - beta_2) * grad_G_w4 ** 2\n",
    "\n",
    "    m12 = beta_1 * m12 + (1 - beta_1) * grad_G_b4\n",
    "    v12 = beta_2 * v12 + (1 - beta_2) * grad_G_b4 ** 2\n",
    "\n",
    "    m13 = beta_1 * m13 + (1 - beta_1) * grad_G_w5\n",
    "    v13 = beta_2 * v13 + (1 - beta_2) * grad_G_w5 ** 2\n",
    "\n",
    "    m14 = beta_1 * m14 + (1 - beta_1) * grad_G_b5\n",
    "    v14 = beta_2 * v14 + (1 - beta_2) * grad_G_b5 ** 2\n",
    "\n",
    "    m15 = beta_1 * m15 + (1 - beta_1) * grad_G_w6\n",
    "    v15 = beta_2 * v15 + (1 - beta_2) * grad_G_w6 ** 2\n",
    "\n",
    "    m16 = beta_1 * m16 + (1 - beta_1) * grad_G_b6\n",
    "    v16 = beta_2 * v16 + (1 - beta_2) * grad_G_b6 ** 2\n",
    "\n",
    "    m17 = beta_1 * m17 + (1 - beta_1) * grad_G_w7\n",
    "    v17 = beta_2 * v17 + (1 - beta_2) * grad_G_w7 ** 2\n",
    "\n",
    "    m18 = beta_1 * m18 + (1 - beta_1) * grad_G_b7\n",
    "    v18 = beta_2 * v18 + (1 - beta_2) * grad_G_b7 ** 2\n",
    "\n",
    "    G_W1 = G_W1 - (learing_rate / (np.sqrt(v5 /(1-beta_2) ) + eps)) * (m5/(1-beta_1))\n",
    "    G_b1 = G_b1 - (learing_rate / (np.sqrt(v6 /(1-beta_2) ) + eps)) * (m6/(1-beta_1))\n",
    "    \n",
    "    G_W2 = G_W2 - (learing_rate / (np.sqrt(v7 /(1-beta_2) ) + eps)) * (m7/(1-beta_1))\n",
    "    G_b2 = G_b2 - (learing_rate / (np.sqrt(v8 /(1-beta_2) ) + eps)) * (m8/(1-beta_1))\n",
    "\n",
    "    G_W3 = G_W3 - (learing_rate / (np.sqrt(v9 /(1-beta_2) ) + eps)) * (m9/(1-beta_1))\n",
    "    G_b3 = G_b3 - (learing_rate / (np.sqrt(v10 /(1-beta_2) ) + eps)) * (m10/(1-beta_1))\n",
    "\n",
    "    G_W4 = G_W4 - (learing_rate / (np.sqrt(v11 /(1-beta_2) ) + eps)) * (m11/(1-beta_1))\n",
    "    G_b4 = G_b4 - (learing_rate / (np.sqrt(v12 /(1-beta_2) ) + eps)) * (m12/(1-beta_1))\n",
    "\n",
    "    G_W5 = G_W5 - (learing_rate / (np.sqrt(v13 /(1-beta_2) ) + eps)) * (m13/(1-beta_1))\n",
    "    G_b5 = G_b5 - (learing_rate / (np.sqrt(v14 /(1-beta_2) ) + eps)) * (m14/(1-beta_1))\n",
    "\n",
    "    G_W6 = G_W6 - (learing_rate / (np.sqrt(v15 /(1-beta_2) ) + eps)) * (m15/(1-beta_1))\n",
    "    G_b6 = G_b6 - (learing_rate / (np.sqrt(v16 /(1-beta_2) ) + eps)) * (m16/(1-beta_1))\n",
    "\n",
    "    G_W7 = G_W7 - (learing_rate / (np.sqrt(v17 /(1-beta_2) ) + eps)) * (m17/(1-beta_1))\n",
    "    G_b7 = G_b7 - (learing_rate / (np.sqrt(v18 /(1-beta_2) ) + eps)) * (m18/(1-beta_1))\n",
    "\n",
    "    # --- Print Error ----\n",
    "    #print(\"Current Iter: \",iter, \" Current D cost:\",D_cost, \" Current G cost: \", G_cost,end='\\r')\n",
    "    \n",
    "    if iter == 0:\n",
    "        learing_rate = learing_rate * 0.01\n",
    "    if iter == 40:\n",
    "        learing_rate = learing_rate * 0.01\n",
    "\n",
    "    # ---- Print to Out put ----\n",
    "    if iter%10 == 0:\n",
    "        \n",
    "        print(\"Current Iter: \",iter, \" Current D cost:\",D_cost, \" Current G cost: \", G_cost,end='\\r')\n",
    "        print('--------- Show Example Result See Tab Above ----------')\n",
    "        print('--------- Wait for the image to load ---------')\n",
    "        Z = np.random.uniform(-1., 1., size=[16, G_input]) \n",
    "\n",
    "        Gl1 = Z.dot(G_W1) + G_b1\n",
    "        Gl1A = arctan(Gl1)\n",
    "        Gl2 = Gl1A.dot(G_W2) + G_b2\n",
    "        Gl2A = ReLu(Gl2)\n",
    "        Gl3 = Gl2A.dot(G_W3) + G_b3\n",
    "        Gl3A = arctan(Gl3)\n",
    "\n",
    "        Gl4 = Gl3A.dot(G_W4) + G_b4\n",
    "        Gl4A = ReLu(Gl4)\n",
    "        Gl5 = Gl4A.dot(G_W5) + G_b5\n",
    "        Gl5A = tanh(Gl5)\n",
    "        Gl6 = Gl5A.dot(G_W6) + G_b6\n",
    "        Gl6A = ReLu(Gl6)\n",
    "        Gl7 = Gl6A.dot(G_W7) + G_b7\n",
    "        \n",
    "        current_fake_data = log(Gl7)\n",
    "        \n",
    "        fig = plot(current_fake_data)\n",
    "        fig.savefig('Click_Me_{}.png'.format(str(iter).zfill(3)+\"_Ginput_\"+str(G_input)+ \\\n",
    "        \"_hiddenone\"+str(hidden_input) + \"_hiddentwo\"+str(hidden_input2) + \"_LR_\" + str(learing_rate)\n",
    "        ), bbox_inches='tight')\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# -- end code --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "7  Implementing GAN (General Adversarial Networks) and Adam Optimizer ",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
